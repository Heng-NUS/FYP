{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:59:02.695400Z",
     "start_time": "2020-04-20T08:59:02.690890Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import smart_open\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import Phrases, LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from palmettopy.palmetto import Palmetto\n",
    "palmetto = Palmetto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:59:03.042531Z",
     "start_time": "2020-04-20T08:59:03.022472Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "labels = []\n",
    "\n",
    "with open('./cluster/SearchSnippets.txt','r') as d_f:\n",
    "    for line in d_f:\n",
    "        if line != '\\n':\n",
    "            docs.append(line)\n",
    "    \n",
    "with open('./cluster/SearchSnippets_label.txt', 'r') as l_f:\n",
    "    for line in l_f:\n",
    "        if line != '\\n':\n",
    "            labels.append(int(line))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:59:07.893393Z",
     "start_time": "2020-04-20T08:59:04.601074Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "for idx in range(len(docs)):\n",
    "    docs[idx] = docs[idx].lower()  # Convert to lowercase.\n",
    "    docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "docs = [[token for token in doc if not token.isnumeric()] for doc in docs]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "docs = [[token for token in doc if len(token) > 1] for doc in docs]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n",
    "\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:59:29.754933Z",
     "start_time": "2020-04-20T08:59:29.514781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:59:31.419067Z",
     "start_time": "2020-04-20T08:59:31.400122Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('doc_info.txt', 'w', encoding='utf-8') as f:\n",
    "    for doc in docs:\n",
    "        f.write(' '.join(doc) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:59:33.155393Z",
     "start_time": "2020-04-20T08:59:33.011913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:59:34.469170Z",
     "start_time": "2020-04-20T08:59:34.465260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 3912\n",
      "Number of documents: 12295\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:10:41.359675Z",
     "start_time": "2020-04-20T09:09:57.278402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 8\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 100\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:10:42.051755Z",
     "start_time": "2020-04-20T09:10:41.990229Z"
    }
   },
   "outputs": [],
   "source": [
    "top_topics = model.top_topics(corpus, topn=10) #, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:10:42.683298Z",
     "start_time": "2020-04-20T09:10:42.677285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "research science edu journal theory page information paper university theoretical \n",
      "art culture system engine history home information fitness music page \n",
      "sport news football com match hockey team club rugby volleyball \n",
      "health business information gov news union social job service disease \n",
      "wikipedia tennis encyclopedia wiki wikipedia_wiki wikipedia_encyclopedia political basketball yahoo wimbledon \n",
      "game com tournament online school amazon book university espn ticket \n",
      "soccer player computer world system score cup software internet republic \n",
      "movie film imdb award equipment space resource gym electrical forum \n"
     ]
    }
   ],
   "source": [
    "topics = []\n",
    "for i in range(len(top_topics)):\n",
    "    a = [x[1] for x in top_topics[i][0]]\n",
    "    topics.append(a)\n",
    "    for x in a:\n",
    "        print(x, end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T07:59:58.695254Z",
     "start_time": "2020-04-20T07:59:58.677749Z"
    }
   },
   "outputs": [],
   "source": [
    "train_corpus = [gensim.models.doc2vec.TaggedDocument(tokens, [i]) for i, tokens in enumerate(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:00:50.563573Z",
     "start_time": "2020-04-20T08:00:50.559018Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = gensim.models.doc2vec.Doc2Vec(vector_size=40, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:00:06.193967Z",
     "start_time": "2020-04-20T08:00:03.386921Z"
    }
   },
   "outputs": [],
   "source": [
    "model2.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:00:37.342734Z",
     "start_time": "2020-04-20T08:00:06.487928Z"
    }
   },
   "outputs": [],
   "source": [
    "model2.train(train_corpus, total_examples=model2.corpus_count, epochs=model2.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:00:37.668369Z",
     "start_time": "2020-04-20T08:00:37.648446Z"
    }
   },
   "outputs": [],
   "source": [
    "docvecs = [model2.docvecs[i] for i in range(len(docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:39:48.553958Z",
     "start_time": "2020-04-20T08:39:48.550832Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:40:01.690226Z",
     "start_time": "2020-04-20T08:40:00.732051Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.fit(docvecs)\n",
    "predicted = kmeans.predict(docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:40:14.290760Z",
     "start_time": "2020-04-20T08:40:14.281562Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster_dict = {}\n",
    "for i,label in enumerate(predicted):\n",
    "    if label in cluster_dict:\n",
    "        cluster_dict[label].append(i)\n",
    "    else:\n",
    "        cluster_dict[label] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:05:19.713459Z",
     "start_time": "2020-04-20T08:05:19.706062Z"
    }
   },
   "outputs": [],
   "source": [
    "def top_words(cluster_dict, dictionary, word_num=10):\n",
    "    all_dict = []\n",
    "    topics = []\n",
    "    for x in range(len(cluster_dict)):\n",
    "        group0 = [dictionary.doc2idx(docs[i]) for i in cluster_dict[x]]\n",
    "        topic_word_count = {}\n",
    "        for doc in group0:\n",
    "            for x in doc:\n",
    "                if x in topic_word_count:\n",
    "                    topic_word_count[x] += 1\n",
    "                else:\n",
    "                    topic_word_count[x] = 1\n",
    "        all_dict.append(topic_word_count)\n",
    "        \n",
    "    for topic_word_count in all_dict:\n",
    "        totoal_count = sum(topic_word_count.values())\n",
    "        tf_idf = {}\n",
    "        for w in topic_word_count.keys():\n",
    "            dfs = 0\n",
    "            for dic in all_dict:\n",
    "                if w in dic:\n",
    "                    dfs += 1\n",
    "            try:\n",
    "                tf = topic_word_count[w] / totoal_count\n",
    "                idf = np.log(len(cluster_dict) / (dfs))\n",
    "                tf_idf[w] = tf * idf\n",
    "            except KeyError:\n",
    "                continue\n",
    "        a = sorted(tf_idf.items(), key=lambda x:x[1], reverse=True)[:word_num]\n",
    "        topic0 = [dictionary[i[0]] for i in a]\n",
    "        topics.append(topic0)\n",
    "        print(' '.join(topic0))\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T08:40:26.843345Z",
     "start_time": "2020-04-20T08:40:26.695182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commodity tax medicare fda insurance tariff fund_budget agency union venture\n",
      "medicare cba union minnesota referee senator economic_development public_health dentist agency\n",
      "cisco mozilla wireless_access client_server zdnet microprocessor ibm sourceforge mspx cache\n",
      "bbc allposters commodity sportsline lyric chron boxing cbs bull forbes\n",
      "britannica union britannica_article descartes communism encyclopaedia_britannica westminster socialism meaning fluid\n",
      "sewing bull sewing_machine chicago_bull speed_test stock_quote tiger commodity client_server ticket\n",
      "stanford_edu mit lecture ocw optic einstein aristotle wolfram maa reasoning\n",
      "lyric girl youtube movie_episode episode piano soundtrack olympic tiger favorite\n"
     ]
    }
   ],
   "source": [
    "topics = top_words(cluster_dict, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:17:29.896797Z",
     "start_time": "2020-04-20T10:15:14.210364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 & research edu science journal theory school university information computer program & 0.424 & 0.256 & 0.680\\\\\\hline\n",
      "2 & movie com music art amazon culture book film video news & 0.316 & 0.248 & 0.564\\\\\\hline\n",
      "3 & computer software web system memory programming internet com intel device & 0.249 & 0.217 & 0.466\\\\\\hline\n",
      "4 & wikipedia political encyclopedia system party wiki wikipedia_wiki democracy wikipedia_encyclopedia government & 0.095 & 0.181 & 0.276\\\\\\hline\n",
      "5 & sport news game football com soccer world match league ticket & 0.360 & 0.254 & 0.614\\\\\\hline\n",
      "6 & business market news service stock trade job information home finance & 0.294 & 0.174 & 0.468\\\\\\hline\n",
      "7 & health information gov cancer news research disease medical drug national & 0.426 & 0.227 & 0.653\\\\\\hline\n",
      "8 & car engine calorie wheel motor electrical income tax model automatic & 0.103 & 0.232 & 0.335\\\\\\hline\n",
      "& & 2.266 & 1.790 & 4.056\\\\\\hline\n"
     ]
    }
   ],
   "source": [
    "cps = []\n",
    "cas = []\n",
    "sums = []\n",
    "for i,topic in enumerate(a):\n",
    "    cp = palmetto.get_coherence(topic,coherence_type=\"cp\")\n",
    "    ca = palmetto.get_coherence(topic, coherence_type=\"ca\")\n",
    "    cps.append(cp)\n",
    "    cas.append(ca)\n",
    "    allsum = cp+ca\n",
    "    sums.append(allsum)\n",
    "    topic = \" \".join(topic)\n",
    "    print(r\"{} & {} & {:.3f} & {:.3f} & {:.3f}\\\\\\hline\".format(i+1, topic, cp, ca, allsum))\n",
    "sum_cp = sum(cps)\n",
    "sum_ca = sum(cas)\n",
    "print(r\"& & {:.3f} & {:.3f} & {:.3f}\\\\\\hline\".format(sum_cp, sum_ca, sum_cp+sum_ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T09:46:02.197798Z",
     "start_time": "2020-04-20T09:46:02.193202Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-24-fdfdea0d1edf>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-fdfdea0d1edf>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    a = \"research edu science journal school theory university information computer program\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "research edu science journal theory school university information computer program\n",
    "movie com music art amazon culture book film video news\n",
    "computer software web system memory programming internet com intel device\n",
    "wikipedia political encyclopedia system party wiki wikipedia_wiki democracy wikipedia_encyclopedia government\n",
    "sport news game football com soccer world match league ticket\n",
    "business market news service stock trade job information home finance\n",
    "health information gov cancer news research disease medical drug national\n",
    "car engine calorie wheel motor electrical income tax model automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:14:07.683935Z",
     "start_time": "2020-04-20T10:14:07.681346Z"
    }
   },
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-20T10:15:01.198308Z",
     "start_time": "2020-04-20T10:15:01.195302Z"
    }
   },
   "outputs": [],
   "source": [
    "a.append(\"car engine calorie wheel motor electrical income tax model automatic\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:07:14.489244Z",
     "start_time": "2020-04-22T12:07:13.294554Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T02:12:46.977702Z",
     "start_time": "2020-04-23T02:12:46.972571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:21:56.390359Z",
     "start_time": "2020-04-22T12:21:56.335790Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zero_() missing 1 required positional arguments: \"input\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-d4d1f9235970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: zero_() missing 1 required positional arguments: \"input\""
     ]
    }
   ],
   "source": [
    "torch.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-22T12:07:51.721642Z",
     "start_time": "2020-04-22T12:07:51.716416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0907, 0.3435])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./un_data/COVID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                    Tweet Id  \\\n0      \"1233417783175778304\"   \n1      \"1233417742520332290\"   \n2      \"1233417741027225602\"   \n3      \"1233417699264356357\"   \n4      \"1233417674274807808\"   \n...                      ...   \n60155  \"1204309839004012544\"   \n60156  \"1204212528810729479\"   \n60157  \"1204206609708331009\"   \n60158  \"1201998948950577152\"   \n60159  \"1200977067266990080\"   \n\n                                               Tweet URL  \\\n0      https://twitter.com/Giussi92/status/1233417783...   \n1      https://twitter.com/LAMofficial/status/1233417...   \n2      https://twitter.com/mitchellvii/status/1233417...   \n3      https://twitter.com/HelenKennedy/status/123341...   \n4      https://twitter.com/W7VOA/status/1233417674274...   \n...                                                  ...   \n60155  https://twitter.com/RevistaArgos/status/120430...   \n60156  https://twitter.com/RobNotRob11/status/1204212...   \n60157  https://twitter.com/timhquotes/status/12042066...   \n60158  https://twitter.com/Baric_Lab/status/120199894...   \n60159  https://twitter.com/thelonevirologi/status/120...   \n\n      Tweet Posted Time (UTC)  \\\n0        28 Feb 2020 15:44:49   \n1        28 Feb 2020 15:44:40   \n2        28 Feb 2020 15:44:39   \n3        28 Feb 2020 15:44:29   \n4        28 Feb 2020 15:44:23   \n...                       ...   \n60155    10 Dec 2019 08:00:15   \n60156    10 Dec 2019 01:33:34   \n60157    10 Dec 2019 01:10:03   \n60158    03 Dec 2019 22:57:36   \n60159    01 Dec 2019 03:17:00   \n\n                                           Tweet Content Tweet Type  \\\n0      Also the entire Swiss Football League is on ho...      Tweet   \n1      World Health Org Official: Trump’s press confe...      Tweet   \n2      I mean, Liberals are cheer-leading this #Coron...      Tweet   \n3      Under repeated questioning, Pompeo refuses to ...      Tweet   \n4      #coronavirus comments now from @larry_kudlow h...      Tweet   \n...                                                  ...        ...   \n60155  El #coronavirus entérico felino es un virus in...      Tweet   \n60156  RT @timhquotes: It's my party, you're invited!...    ReTweet   \n60157  It's my party, you're invited!\\n\\nPS, this is ...      Tweet   \n60158  Amy’s a survivor! #bariclab #pnnl #movingon #c...      Tweet   \n60159  A review of asymptomatic and sub-clinical Midd...      Tweet   \n\n                    Client  Retweets Received  Likes Received  \\\n0       Twitter for iPhone                  0               0   \n1          Twitter Web App                  0               0   \n2          Twitter Web App                 23              64   \n3       Twitter for iPhone                  4              11   \n4       Twitter for iPhone                  0               0   \n...                    ...                ...             ...   \n60155       Hootsuite Inc.                  0               0   \n60156  Twitter for Android                  0               0   \n60157  Twitter for Android                  2              28   \n60158   Twitter for iPhone                  1              17   \n60159   Twitter for iPhone                  0               0   \n\n                           Tweet Location  Lat  ...               User Id  \\\n0                                     NaN  NaN  ...          \"1556856595\"   \n1                      Los Angeles CA USA  NaN  ...           \"113738369\"   \n2                               Miami, FL  NaN  ...            \"17980523\"   \n3                  NYC and the North Fork  NaN  ...             \"2199541\"   \n4      James S. Brady Press Briefing Room  NaN  ...            \"17919393\"   \n...                                   ...  ...  ...                   ...   \n60155                                 NaN  NaN  ...           \"588410190\"   \n60156                                 NaN  NaN  ...          \"4719933867\"   \n60157                    Jackson Hole, WY  NaN  ...          \"2195288012\"   \n60158                     Chapel Hill, NC  NaN  ...  \"989521438825746433\"   \n60159                                 USA  NaN  ...          \"2414645220\"   \n\n                        Name      Screen Name  \\\n0           Giuseppe Gentile         Giussi92   \n1      London After Midnight      LAMofficial   \n2              Bill Mitchell      mitchellvii   \n3              Helen Kennedy     HelenKennedy   \n4               Steve Herman            W7VOA   \n...                      ...              ...   \n60155          Revista Argos     RevistaArgos   \n60156     Serving Suggestion      RobNotRob11   \n60157   Tim Heidecker Quotes       timhquotes   \n60158       Baric Laboratory        Baric_Lab   \n60159      thelonevirologist  thelonevirologi   \n\n                                                User Bio  \\\n0                                                    NaN   \n1      London After Midnight is a music project by wr...   \n2      Host of YourVoice™ America at http://yourvoice...   \n3      Newspaperman (ex NY Daily News &amp; Boston He...   \n4      @WhiteHouse bureau chief @VOANews. Member: @aa...   \n...                                                  ...   \n60155  La revista de los veterinarios de animales de ...   \n60156  6-and-a-half-foot tall, awkwardly shaped man. ...   \n60157  Quotes from our favorite weird boy. Awesome pa...   \n60158  Researching SARS-CoV, MERS CoV, Dengue, Zika a...   \n60159  Virologist.Likes history, hiking &amp; a good ...   \n\n      Verified or Non-Verified                          Profile URL  \\\n0                     Verified         https://twitter.com/Giussi92   \n1                     Verified      https://twitter.com/LAMofficial   \n2                     Verified      https://twitter.com/mitchellvii   \n3                     Verified     https://twitter.com/HelenKennedy   \n4                     Verified            https://twitter.com/W7VOA   \n...                        ...                                  ...   \n60155             Non-Verified     https://twitter.com/RevistaArgos   \n60156             Non-Verified      https://twitter.com/RobNotRob11   \n60157             Non-Verified       https://twitter.com/timhquotes   \n60158             Non-Verified        https://twitter.com/Baric_Lab   \n60159             Non-Verified  https://twitter.com/thelonevirologi   \n\n      Protected or Non-protected User Followers User Following  \\\n0                  Non-Protected           3071            100   \n1                  Non-Protected           4189             84   \n2                  Non-Protected         534045          10037   \n3                  Non-Protected          27704           1060   \n4                  Non-Protected          94269           1999   \n...                          ...            ...            ...   \n60155              Non-Protected           4236            313   \n60156              Non-Protected             37            259   \n60157              Non-Protected           2583            822   \n60158              Non-Protected           1326             82   \n60159              Non-Protected           6527           1233   \n\n       User Account Creation Date  \n0            30 Jun 2013 00:27:50  \n1            12 Feb 2010 21:43:17  \n2            09 Dec 2008 01:54:21  \n3            25 Mar 2007 19:14:46  \n4            06 Dec 2008 08:56:45  \n...                           ...  \n60155        23 May 2012 14:30:12  \n60156        06 Jan 2016 01:12:42  \n60157        15 Nov 2013 03:20:11  \n60158        26 Apr 2018 15:07:50  \n60159        27 Mar 2014 16:58:36  \n\n[60160 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet Id</th>\n      <th>Tweet URL</th>\n      <th>Tweet Posted Time (UTC)</th>\n      <th>Tweet Content</th>\n      <th>Tweet Type</th>\n      <th>Client</th>\n      <th>Retweets Received</th>\n      <th>Likes Received</th>\n      <th>Tweet Location</th>\n      <th>Lat</th>\n      <th>...</th>\n      <th>User Id</th>\n      <th>Name</th>\n      <th>Screen Name</th>\n      <th>User Bio</th>\n      <th>Verified or Non-Verified</th>\n      <th>Profile URL</th>\n      <th>Protected or Non-protected</th>\n      <th>User Followers</th>\n      <th>User Following</th>\n      <th>User Account Creation Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"1233417783175778304\"</td>\n      <td>https://twitter.com/Giussi92/status/1233417783...</td>\n      <td>28 Feb 2020 15:44:49</td>\n      <td>Also the entire Swiss Football League is on ho...</td>\n      <td>Tweet</td>\n      <td>Twitter for iPhone</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"1556856595\"</td>\n      <td>Giuseppe Gentile</td>\n      <td>Giussi92</td>\n      <td>NaN</td>\n      <td>Verified</td>\n      <td>https://twitter.com/Giussi92</td>\n      <td>Non-Protected</td>\n      <td>3071</td>\n      <td>100</td>\n      <td>30 Jun 2013 00:27:50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"1233417742520332290\"</td>\n      <td>https://twitter.com/LAMofficial/status/1233417...</td>\n      <td>28 Feb 2020 15:44:40</td>\n      <td>World Health Org Official: Trump’s press confe...</td>\n      <td>Tweet</td>\n      <td>Twitter Web App</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Los Angeles CA USA</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"113738369\"</td>\n      <td>London After Midnight</td>\n      <td>LAMofficial</td>\n      <td>London After Midnight is a music project by wr...</td>\n      <td>Verified</td>\n      <td>https://twitter.com/LAMofficial</td>\n      <td>Non-Protected</td>\n      <td>4189</td>\n      <td>84</td>\n      <td>12 Feb 2010 21:43:17</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"1233417741027225602\"</td>\n      <td>https://twitter.com/mitchellvii/status/1233417...</td>\n      <td>28 Feb 2020 15:44:39</td>\n      <td>I mean, Liberals are cheer-leading this #Coron...</td>\n      <td>Tweet</td>\n      <td>Twitter Web App</td>\n      <td>23</td>\n      <td>64</td>\n      <td>Miami, FL</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"17980523\"</td>\n      <td>Bill Mitchell</td>\n      <td>mitchellvii</td>\n      <td>Host of YourVoice™ America at http://yourvoice...</td>\n      <td>Verified</td>\n      <td>https://twitter.com/mitchellvii</td>\n      <td>Non-Protected</td>\n      <td>534045</td>\n      <td>10037</td>\n      <td>09 Dec 2008 01:54:21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"1233417699264356357\"</td>\n      <td>https://twitter.com/HelenKennedy/status/123341...</td>\n      <td>28 Feb 2020 15:44:29</td>\n      <td>Under repeated questioning, Pompeo refuses to ...</td>\n      <td>Tweet</td>\n      <td>Twitter for iPhone</td>\n      <td>4</td>\n      <td>11</td>\n      <td>NYC and the North Fork</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"2199541\"</td>\n      <td>Helen Kennedy</td>\n      <td>HelenKennedy</td>\n      <td>Newspaperman (ex NY Daily News &amp;amp; Boston He...</td>\n      <td>Verified</td>\n      <td>https://twitter.com/HelenKennedy</td>\n      <td>Non-Protected</td>\n      <td>27704</td>\n      <td>1060</td>\n      <td>25 Mar 2007 19:14:46</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"1233417674274807808\"</td>\n      <td>https://twitter.com/W7VOA/status/1233417674274...</td>\n      <td>28 Feb 2020 15:44:23</td>\n      <td>#coronavirus comments now from @larry_kudlow h...</td>\n      <td>Tweet</td>\n      <td>Twitter for iPhone</td>\n      <td>0</td>\n      <td>0</td>\n      <td>James S. Brady Press Briefing Room</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"17919393\"</td>\n      <td>Steve Herman</td>\n      <td>W7VOA</td>\n      <td>@WhiteHouse bureau chief @VOANews. Member: @aa...</td>\n      <td>Verified</td>\n      <td>https://twitter.com/W7VOA</td>\n      <td>Non-Protected</td>\n      <td>94269</td>\n      <td>1999</td>\n      <td>06 Dec 2008 08:56:45</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60155</th>\n      <td>\"1204309839004012544\"</td>\n      <td>https://twitter.com/RevistaArgos/status/120430...</td>\n      <td>10 Dec 2019 08:00:15</td>\n      <td>El #coronavirus entérico felino es un virus in...</td>\n      <td>Tweet</td>\n      <td>Hootsuite Inc.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"588410190\"</td>\n      <td>Revista Argos</td>\n      <td>RevistaArgos</td>\n      <td>La revista de los veterinarios de animales de ...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/RevistaArgos</td>\n      <td>Non-Protected</td>\n      <td>4236</td>\n      <td>313</td>\n      <td>23 May 2012 14:30:12</td>\n    </tr>\n    <tr>\n      <th>60156</th>\n      <td>\"1204212528810729479\"</td>\n      <td>https://twitter.com/RobNotRob11/status/1204212...</td>\n      <td>10 Dec 2019 01:33:34</td>\n      <td>RT @timhquotes: It's my party, you're invited!...</td>\n      <td>ReTweet</td>\n      <td>Twitter for Android</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"4719933867\"</td>\n      <td>Serving Suggestion</td>\n      <td>RobNotRob11</td>\n      <td>6-and-a-half-foot tall, awkwardly shaped man. ...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/RobNotRob11</td>\n      <td>Non-Protected</td>\n      <td>37</td>\n      <td>259</td>\n      <td>06 Jan 2016 01:12:42</td>\n    </tr>\n    <tr>\n      <th>60157</th>\n      <td>\"1204206609708331009\"</td>\n      <td>https://twitter.com/timhquotes/status/12042066...</td>\n      <td>10 Dec 2019 01:10:03</td>\n      <td>It's my party, you're invited!\\n\\nPS, this is ...</td>\n      <td>Tweet</td>\n      <td>Twitter for Android</td>\n      <td>2</td>\n      <td>28</td>\n      <td>Jackson Hole, WY</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"2195288012\"</td>\n      <td>Tim Heidecker Quotes</td>\n      <td>timhquotes</td>\n      <td>Quotes from our favorite weird boy. Awesome pa...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/timhquotes</td>\n      <td>Non-Protected</td>\n      <td>2583</td>\n      <td>822</td>\n      <td>15 Nov 2013 03:20:11</td>\n    </tr>\n    <tr>\n      <th>60158</th>\n      <td>\"1201998948950577152\"</td>\n      <td>https://twitter.com/Baric_Lab/status/120199894...</td>\n      <td>03 Dec 2019 22:57:36</td>\n      <td>Amy’s a survivor! #bariclab #pnnl #movingon #c...</td>\n      <td>Tweet</td>\n      <td>Twitter for iPhone</td>\n      <td>1</td>\n      <td>17</td>\n      <td>Chapel Hill, NC</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"989521438825746433\"</td>\n      <td>Baric Laboratory</td>\n      <td>Baric_Lab</td>\n      <td>Researching SARS-CoV, MERS CoV, Dengue, Zika a...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/Baric_Lab</td>\n      <td>Non-Protected</td>\n      <td>1326</td>\n      <td>82</td>\n      <td>26 Apr 2018 15:07:50</td>\n    </tr>\n    <tr>\n      <th>60159</th>\n      <td>\"1200977067266990080\"</td>\n      <td>https://twitter.com/thelonevirologi/status/120...</td>\n      <td>01 Dec 2019 03:17:00</td>\n      <td>A review of asymptomatic and sub-clinical Midd...</td>\n      <td>Tweet</td>\n      <td>Twitter for iPhone</td>\n      <td>0</td>\n      <td>0</td>\n      <td>USA</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>\"2414645220\"</td>\n      <td>thelonevirologist</td>\n      <td>thelonevirologi</td>\n      <td>Virologist.Likes history, hiking &amp;amp; a good ...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/thelonevirologi</td>\n      <td>Non-Protected</td>\n      <td>6527</td>\n      <td>1233</td>\n      <td>27 Mar 2014 16:58:36</td>\n    </tr>\n  </tbody>\n</table>\n<p>60160 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['Tweet Id', 'Tweet URL', 'Tweet Posted Time (UTC)', 'Tweet Content',\n       'Tweet Type', 'Client', 'Retweets Received', 'Likes Received',\n       'Tweet Location', 'Lat', 'Long', 'Tweet Language', 'User Id', 'Name',\n       'Screen Name', 'User Bio', 'Verified or Non-Verified', 'Profile URL',\n       'Protected or Non-protected', 'User Followers', 'User Following',\n       'User Account Creation Date'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data[(data['Tweet Language'] == 'English') & (data['Tweet Type'] == \"Tweet\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs['Tweet Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'World Health Org Official: Trump’s press conference on #coronavirus ‘incoherent’\\nWorld Health Organization Special Adviser to the Director Dr. Ezekiel Emanuel says \"I found most of what [Trump] said incoherent.\"\\nhttps://t.co/v4WIBW9Fld'"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'./un_data/covid.txt', 'w', encoding='utf-8') as f:\n",
    "    for doc in docs:\n",
    "        f.write(r'\\\\'.join(doc.split('\\\\')) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'World Health Org Official: Trump’s press conference on #coronavirus ‘incoherent’\\nWorld Health Organization Special Adviser to the Director Dr. Ezekiel Emanuel says \"I found most of what [Trump] said incoherent.\"\\nhttps://t.co/v4WIBW9Fld'"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "r'\\\\'.join(docs[1].split('\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python36564bite879fb2474af4702a9a8f03824870030"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}