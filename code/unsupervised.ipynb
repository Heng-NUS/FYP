{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T11:15:52.719932Z",
     "start_time": "2020-03-24T11:15:50.879701Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import gensim\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:26:31.012465Z",
     "start_time": "2020-03-25T09:26:31.006408Z"
    }
   },
   "outputs": [],
   "source": [
    "import smart_open\n",
    "from nltk.corpus import stopwords\n",
    "STOP_WORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T12:31:06.673650Z",
     "start_time": "2020-03-24T12:31:06.669186Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line, min_len=3)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T12:31:57.538357Z",
     "start_time": "2020-03-24T12:31:57.487818Z"
    }
   },
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(\"/Volumes/White/training/bbchealth.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T12:32:53.420331Z",
     "start_time": "2020-03-24T12:32:53.349862Z"
    }
   },
   "outputs": [],
   "source": [
    "test_corpus = list(read_corpus(\"/Volumes/White/training/cbchealth.txt\", tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:11:51.735046Z",
     "start_time": "2020-03-25T14:11:51.731608Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:11:55.971946Z",
     "start_time": "2020-03-25T14:11:54.946167Z"
    }
   },
   "outputs": [],
   "source": [
    "model2.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:12:15.309275Z",
     "start_time": "2020-03-25T14:12:06.836555Z"
    }
   },
   "outputs": [],
   "source": [
    "model2.train(train_corpus, total_examples=model2.corpus_count, epochs=model2.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:15:20.823411Z",
     "start_time": "2020-03-25T14:15:20.818922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2VecVocab at 0x134f44f28>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:15:39.114017Z",
     "start_time": "2020-03-25T14:15:39.100749Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Doc2VecVocab' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-c1411fd86a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Doc2VecVocab' object is not iterable"
     ]
    }
   ],
   "source": [
    "for word in model2.vocabulary:\n",
    "    print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T12:45:56.105321Z",
     "start_time": "2020-03-24T12:45:15.559440Z"
    }
   },
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T12:46:05.395290Z",
     "start_time": "2020-03-24T12:46:05.390312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 299, 1: 101, 2: 79, 3: 73, 6: 52, 5: 49, 4: 47, 7: 44, 8: 43, 10: 42, 9: 40, 11: 37, 17: 37, 14: 37, 13: 33, 27: 33, 21: 32, 19: 31, 20: 30, 12: 30, 26: 29, 47: 29, 18: 28, 24: 28, 15: 27, 29: 26, 23: 26, 40: 24, 41: 24, 22: 24, 32: 23, 48: 23, 25: 22, 33: 22, 43: 22, 79: 21, 16: 21, 28: 21, 54: 20, 42: 20, 30: 19, 31: 18, 78: 18, 35: 18, 38: 18, 55: 17, 34: 17, 36: 17, 60: 17, 50: 17, 84: 17, 94: 17, 68: 17, 45: 17, 90: 16, 88: 16, 70: 16, 100: 16, 66: 16, 52: 15, 37: 15, 106: 15, 73: 15, 138: 15, 61: 15, 46: 15, 82: 14, 58: 14, 101: 14, 51: 14, 80: 14, 71: 14, 111: 14, 39: 14, 91: 14, 115: 14, 112: 14, 74: 13, 107: 13, 76: 13, 93: 13, 75: 13, 110: 13, 127: 13, 67: 13, 179: 13, 81: 13, 92: 13, 63: 13, 118: 13, 59: 13, 65: 13, 44: 12, 89: 12, 166: 12, 133: 12, 139: 12, 124: 12, 121: 12, 120: 12, 102: 12, 56: 12, 53: 12, 159: 11, 131: 11, 155: 11, 69: 11, 174: 11, 119: 11, 98: 11, 62: 11, 104: 11, 128: 11, 77: 11, 87: 11, 156: 11, 147: 10, 64: 10, 132: 10, 130: 10, 99: 10, 141: 10, 135: 10, 142: 10, 200: 10, 114: 10, 199: 10, 49: 10, 125: 10, 137: 10, 96: 9, 180: 9, 187: 9, 109: 9, 144: 9, 209: 9, 83: 9, 95: 9, 164: 9, 108: 9, 136: 9, 190: 9, 85: 9, 260: 9, 116: 9, 165: 9, 57: 9, 158: 8, 134: 8, 72: 8, 140: 8, 97: 8, 160: 8, 117: 8, 175: 8, 203: 8, 225: 8, 245: 8, 197: 8, 161: 8, 113: 7, 153: 7, 168: 7, 208: 7, 204: 7, 167: 7, 151: 7, 223: 7, 269: 7, 152: 7, 122: 7, 184: 7, 126: 7, 183: 7, 234: 6, 103: 6, 198: 6, 170: 6, 254: 6, 129: 6, 238: 6, 177: 6, 86: 6, 218: 6, 291: 6, 150: 6, 202: 6, 189: 6, 172: 6, 123: 6, 163: 6, 217: 5, 146: 5, 325: 5, 195: 5, 292: 5, 148: 5, 143: 5, 196: 5, 173: 5, 181: 5, 244: 5, 263: 5, 145: 5, 149: 5, 290: 5, 105: 5, 193: 5, 169: 5, 201: 5, 154: 5, 206: 5, 305: 5, 211: 5, 280: 5, 219: 4, 205: 4, 186: 4, 185: 4, 210: 4, 232: 4, 212: 4, 304: 4, 191: 4, 229: 4, 237: 4, 178: 4, 258: 4, 272: 4, 240: 4, 282: 4, 215: 4, 276: 4, 271: 4, 268: 3, 251: 3, 262: 3, 228: 3, 221: 3, 295: 3, 410: 3, 453: 3, 264: 3, 176: 3, 300: 3, 302: 3, 306: 3, 250: 3, 355: 3, 265: 3, 318: 3, 322: 3, 241: 3, 216: 3, 231: 3, 278: 3, 253: 3, 277: 3, 351: 3, 246: 3, 273: 3, 314: 3, 157: 3, 257: 3, 289: 3, 316: 3, 171: 3, 227: 3, 323: 3, 274: 3, 162: 3, 207: 3, 249: 3, 267: 3, 281: 3, 194: 3, 224: 3, 236: 3, 308: 3, 401: 2, 356: 2, 261: 2, 266: 2, 407: 2, 286: 2, 442: 2, 332: 2, 333: 2, 242: 2, 270: 2, 489: 2, 330: 2, 182: 2, 363: 2, 288: 2, 309: 2, 369: 2, 432: 2, 372: 2, 373: 2, 424: 2, 390: 2, 259: 2, 342: 2, 256: 2, 319: 2, 284: 2, 324: 2, 239: 2, 287: 2, 339: 2, 296: 2, 360: 2, 233: 2, 416: 2, 275: 2, 503: 2, 371: 2, 255: 2, 331: 2, 220: 2, 226: 2, 328: 2, 378: 2, 327: 2, 335: 2, 213: 2, 299: 2, 469: 2, 447: 2, 414: 2, 230: 2, 584: 2, 188: 2, 477: 2, 449: 2, 222: 2, 365: 2, 394: 2, 301: 2, 298: 2, 336: 2, 367: 2, 3192: 2, 370: 1, 353: 1, 192: 1, 1034: 1, 374: 1, 313: 1, 481: 1, 321: 1, 3582: 1, 3514: 1, 1024: 1, 2183: 1, 320: 1, 761: 1, 859: 1, 303: 1, 3569: 1, 607: 1, 731: 1, 252: 1, 482: 1, 514: 1, 533: 1, 375: 1, 496: 1, 3799: 1, 682: 1, 411: 1, 2976: 1, 3776: 1, 214: 1, 3579: 1, 3801: 1, 531: 1, 3322: 1, 434: 1, 3235: 1, 599: 1, 502: 1, 283: 1, 408: 1, 557: 1, 598: 1, 329: 1, 555: 1, 383: 1, 435: 1, 1781: 1, 545: 1, 1046: 1, 368: 1, 536: 1, 2506: 1, 513: 1, 409: 1, 748: 1, 3331: 1, 1068: 1, 506: 1, 459: 1, 294: 1, 2746: 1, 690: 1, 431: 1, 317: 1, 427: 1, 562: 1, 404: 1, 3733: 1, 463: 1, 343: 1, 764: 1, 589: 1, 1203: 1, 566: 1, 312: 1, 412: 1, 534: 1, 881: 1, 243: 1, 293: 1, 971: 1, 2349: 1, 326: 1, 608: 1, 499: 1, 3490: 1, 3485: 1, 3730: 1, 666: 1, 393: 1, 3230: 1, 1750: 1, 461: 1, 615: 1, 2374: 1, 349: 1, 554: 1, 392: 1, 474: 1, 708: 1, 247: 1, 490: 1, 3435: 1, 454: 1, 528: 1, 3311: 1, 3120: 1, 311: 1, 310: 1, 625: 1, 358: 1, 402: 1, 426: 1, 399: 1, 509: 1, 315: 1, 437: 1, 483: 1, 3124: 1, 346: 1, 565: 1, 471: 1, 415: 1, 376: 1, 3768: 1, 457: 1, 3502: 1, 941: 1, 428: 1, 478: 1, 3506: 1, 2409: 1, 834: 1, 3830: 1, 385: 1, 235: 1, 3780: 1, 297: 1, 397: 1, 341: 1, 556: 1, 660: 1, 559: 1, 831: 1, 441: 1, 530: 1, 611: 1, 403: 1, 386: 1, 1036: 1, 3646: 1, 907: 1, 479: 1, 307: 1, 3691: 1, 782: 1, 467: 1, 743: 1, 605: 1, 364: 1, 875: 1, 1071: 1, 352: 1, 626: 1, 775: 1, 529: 1, 3744: 1, 248: 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T13:14:53.606242Z",
     "start_time": "2020-03-24T13:14:53.600984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (3928): «diff manslaughter inquiry call»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d50,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (1913, 0.9228657484054565): «hospital deaths inquiry announced»\n",
      "\n",
      "SECOND-MOST (3245, 0.9043088555335999): «trust apologises over dna failings»\n",
      "\n",
      "MEDIAN (135, 0.8058278560638428): «testosterone boost could cut deaths»\n",
      "\n",
      "LEAST (1849, -0.890856146812439): «audio uk mum spent to have girl»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T13:17:45.860039Z",
     "start_time": "2020-03-24T13:17:45.854844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (18): «public back tax rises to fund nhs»\n",
      "\n",
      "Similar Document (532, 0.7212491631507874): «video could volunteers help crisis»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:15:09.146656Z",
     "start_time": "2020-03-25T09:15:09.131375Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LdaModel' object has no attribute 'infer_vector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-02f73b3b0fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdoc_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_corpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minferred_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minferred_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compare and print the most/median/least similar documents from the train corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LdaModel' object has no attribute 'infer_vector'"
     ]
    }
   ],
   "source": [
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T05:10:33.174958Z",
     "start_time": "2020-03-25T05:10:33.170647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2VecVocab at 0x12a0f0390>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T06:40:37.001431Z",
     "start_time": "2020-03-25T06:40:36.996757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3741"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:28:38.003062Z",
     "start_time": "2020-03-25T09:28:37.991438Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = [[token for token in doc if not token.isnumeric()] for doc in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:28:38.658544Z",
     "start_time": "2020-03-25T09:28:38.578229Z"
    }
   },
   "outputs": [],
   "source": [
    "docs = [[token for token in doc if token not in STOP_WORDS and len(token) > 1] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:28:40.583193Z",
     "start_time": "2020-03-25T09:28:40.461639Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:28:42.299078Z",
     "start_time": "2020-03-25T09:28:42.116640Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "bigram = Phrases(docs, min_count=20)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:28:44.364135Z",
     "start_time": "2020-03-25T09:28:44.293179Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:28:46.011249Z",
     "start_time": "2020-03-25T09:28:45.978709Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:28:46.994313Z",
     "start_time": "2020-03-25T09:28:46.990658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 547\n",
      "Number of documents: 3741\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:29:13.758249Z",
     "start_time": "2020-03-25T09:28:49.856498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train LDA model.\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 5\n",
    "chunksize = 2000\n",
    "passes = 50\n",
    "iterations = 500\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:34:26.904913Z",
     "start_time": "2020-03-25T09:34:26.880221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -7.6332.\n",
      "[([(0.03730305, 'study'),\n",
      "   (0.027884427, 'health'),\n",
      "   (0.02675366, 'child'),\n",
      "   (0.02642206, 'risk'),\n",
      "   (0.022995073, 'may'),\n",
      "   (0.022529446, 'say'),\n",
      "   (0.021927454, 'flu'),\n",
      "   (0.020281803, 'canada'),\n",
      "   (0.019442543, 'find'),\n",
      "   (0.018828705, 'heart')],\n",
      "  -3.898933885195516),\n",
      " ([(0.05046783, 'health'),\n",
      "   (0.047932595, 'patient'),\n",
      "   (0.033811655, 'care'),\n",
      "   (0.027102731, 'hospital'),\n",
      "   (0.026161684, 'say'),\n",
      "   (0.025588393, 'help'),\n",
      "   (0.020499807, 'woman'),\n",
      "   (0.018278828, 'canada'),\n",
      "   (0.016977787, 'cancer'),\n",
      "   (0.016194953, 'get')],\n",
      "  -4.29935486905076),\n",
      " ([(0.11225357, 'ebola'),\n",
      "   (0.04032292, 'doctor'),\n",
      "   (0.039274562, 'outbreak'),\n",
      "   (0.028245462, 'say'),\n",
      "   (0.022619862, 'ebola_outbreak'),\n",
      "   (0.02203843, 'health'),\n",
      "   (0.01969455, 'vaccine'),\n",
      "   (0.0174284, 'mental'),\n",
      "   (0.014844919, 'virus'),\n",
      "   (0.014119089, 'case')],\n",
      "  -5.8833361757886085),\n",
      " ([(0.021932602, 'life'),\n",
      "   (0.021549134, 'doctor'),\n",
      "   (0.019754348, 'say'),\n",
      "   (0.017977837, 'quebec'),\n",
      "   (0.01626951, 'recalled'),\n",
      "   (0.01564443, 'concussion'),\n",
      "   (0.015573472, 'could'),\n",
      "   (0.015048969, 'teen'),\n",
      "   (0.014772583, 'rule'),\n",
      "   (0.013150468, 'safety')],\n",
      "  -11.80511467788033),\n",
      " ([(0.04213287, 'cancer'),\n",
      "   (0.037818488, 'medical'),\n",
      "   (0.0316229, 'case'),\n",
      "   (0.025426444, 'food'),\n",
      "   (0.020582687, 'measles'),\n",
      "   (0.020062573, 'kid'),\n",
      "   (0.019437311, 'marijuana'),\n",
      "   (0.019235175, 'school'),\n",
      "   (0.017117942, 'man'),\n",
      "   (0.014271209, 'death')],\n",
      "  -12.279290665680108)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus, topn=10) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:36:45.995616Z",
     "start_time": "2020-03-25T09:36:45.991153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics[0][0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:41:10.209532Z",
     "start_time": "2020-03-25T09:41:10.202856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study health child risk may say flu canada find heart -3.90.\n",
      "health patient care hospital say help woman canada cancer get -4.30.\n",
      "ebola doctor outbreak say ebola_outbreak health vaccine mental virus case -5.88.\n",
      "life doctor say quebec recalled concussion could teen rule safety -11.81.\n",
      "cancer medical case food measles kid marijuana school man death -12.28.\n"
     ]
    }
   ],
   "source": [
    "for data in top_topics:\n",
    "    words, coh = data\n",
    "    for word in words:\n",
    "        print(word[1],end=' ')\n",
    "    print('%.2f.' % coh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T09:20:58.211530Z",
     "start_time": "2020-03-25T09:20:58.207638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function top_topics in module gensim.models.ldamodel:\n",
      "\n",
      "top_topics(self, corpus=None, texts=None, dictionary=None, window_size=None, coherence='u_mass', topn=20, processes=-1)\n",
      "    Get the topics with the highest coherence score the coherence for each topic.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    corpus : iterable of list of (int, float), optional\n",
      "        Corpus in BoW format.\n",
      "    texts : list of list of str, optional\n",
      "        Tokenized texts, needed for coherence models that use sliding window based (i.e. coherence=`c_something`)\n",
      "        probability estimator .\n",
      "    dictionary : :class:`~gensim.corpora.dictionary.Dictionary`, optional\n",
      "        Gensim dictionary mapping of id word to create corpus.\n",
      "        If `model.id2word` is present, this is not needed. If both are provided, passed `dictionary` will be used.\n",
      "    window_size : int, optional\n",
      "        Is the size of the window to be used for coherence measures using boolean sliding window as their\n",
      "        probability estimator. For 'u_mass' this doesn't matter.\n",
      "        If None - the default window sizes are used which are: 'c_v' - 110, 'c_uci' - 10, 'c_npmi' - 10.\n",
      "    coherence : {'u_mass', 'c_v', 'c_uci', 'c_npmi'}, optional\n",
      "        Coherence measure to be used.\n",
      "        Fastest method - 'u_mass', 'c_uci' also known as `c_pmi`.\n",
      "        For 'u_mass' corpus should be provided, if texts is provided, it will be converted to corpus\n",
      "        using the dictionary. For 'c_v', 'c_uci' and 'c_npmi' `texts` should be provided (`corpus` isn't needed)\n",
      "    topn : int, optional\n",
      "        Integer corresponding to the number of top words to be extracted from each topic.\n",
      "    processes : int, optional\n",
      "        Number of processes to use for probability estimation phase, any value less than 1 will be interpreted as\n",
      "        num_cpus - 1.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    list of (list of (int, str), float)\n",
      "        Each element in the list is a pair of a topic representation and its coherence score. Topic representations\n",
      "        are distributions of words, represented as a list of pairs of word IDs and their probabilities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LdaModel.top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T10:19:38.973274Z",
     "start_time": "2020-03-25T10:19:38.523182Z"
    }
   },
   "outputs": [],
   "source": [
    "result = model.inference(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T10:20:15.862766Z",
     "start_time": "2020-03-25T10:20:15.858394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[4.202327  , 0.14931256, 0.1811558 , 0.17285907, 0.13248737],\n",
      "       [0.20737213, 0.14881411, 0.17966826, 0.17013313, 1.1322451 ],\n",
      "       [0.21157056, 0.14905141, 0.18271449, 3.1623259 , 0.13253179],\n",
      "       ...,\n",
      "       [1.2044965 , 0.14944501, 0.18024164, 0.17137441, 0.13267583],\n",
      "       [0.20907094, 0.14918493, 0.18008256, 1.1696776 , 2.1300695 ],\n",
      "       [0.21486135, 0.1490978 , 0.1811795 , 2.161536  , 2.1314466 ]],\n",
      "      dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pprint(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T10:25:21.081089Z",
     "start_time": "2020-03-25T10:25:21.078245Z"
    }
   },
   "outputs": [],
   "source": [
    "result = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T10:32:20.710974Z",
     "start_time": "2020-03-25T10:32:20.704433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(result==np.max(result,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T10:29:14.615991Z",
     "start_time": "2020-03-25T10:29:14.610985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.202327 , 1.1322451, 3.1623259, ..., 1.2044965, 2.1300695,\n",
       "       2.161536 ], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(result,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T11:02:08.705088Z",
     "start_time": "2020-03-25T11:02:08.048160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.107740176398475"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.log_perplexity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T11:15:05.296441Z",
     "start_time": "2020-03-25T11:15:05.289984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study health child risk may say flu canada find heart \n",
      "cancer medical case food measles kid marijuana school man death \n",
      "ebola doctor outbreak say ebola_outbreak health vaccine mental virus case \n",
      "health patient care hospital say help woman canada cancer get \n",
      "life doctor say quebec recalled concussion could teen rule safety \n"
     ]
    }
   ],
   "source": [
    "for i in range(num_topics):\n",
    "    for x in model.show_topic(i):\n",
    "        print(x[0], end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
